services:
  airflow-db:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - airflow_net

  redis:
    image: redis:6-alpine
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    restart: unless-stopped  # Đảm bảo Redis tự động khởi động lại khi gặp sự cố
    volumes:
      - redis_data:/data
    networks:
      - airflow_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]  # Kiểm tra Redis có trả lời "PONG"
      interval: 5s  # Kiểm tra mỗi 5 giây
      timeout: 5s   # Đặt thời gian chờ tối đa là 5 giây
      retries: 5    # Nếu không có phản hồi, thử lại 5 lần trước khi đánh dấu là không khỏe


  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - airflow_net

  hive-metastore-db:
    image: postgres:13
    container_name: hive-metastore-db
    environment:
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
      - POSTGRES_DB=metastore
    volumes:
      - hive_metastore_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - airflow_net

  hive-metastore:
    build:
      context: .
      dockerfile: ./docker/hive-metastore/Dockerfile
    container_name: hive-metastore
    ports:
      - "9083:9083"
    environment:
      HIVE_METASTORE_DB_HOST: hive-metastore-db
      HIVE_METASTORE_DB_PORT: 5432
      HIVE_METASTORE_DB_USER: hive
      HIVE_METASTORE_DB_PASSWORD: hive
      HIVE_METASTORE_DB_NAME: metastore
    depends_on:
      hive-metastore-db:
        condition: service_healthy
    volumes:
      - ./data/hive-warehouse:/opt/hive/data/warehouse
    networks:
      - airflow_net
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 10s
      timeout: 5s
      retries: 5

  trino:
    image: trinodb/trino:473
    container_name: trino
    ports:
      - "8080:8080"
    volumes:
      - ./docker/trino/plugin/hive:/usr/lib/trino/plugin/hive
      - ./docker/hive-metastore/hadoop-lib:/usr/lib/trino/hadoop-lib
      - ./docker/trino/catalog:/etc/trino/catalog
      - ./docker/trino/etc:/etc/trino
      - ./docker/trino/hadoop-lib/core-site.xml:/etc/hadoop/conf/core-site.xml
      - ./docker/hive-metastore/hive-site.xml:/etc/hive/conf/hive-site.xml
      - ./docker/trino/plugin/delta:/usr/lib/trino/plugin/delta-lake
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    depends_on:
      hive-metastore:
        condition: service_healthy
    networks:
      - airflow_net

  airflow-init:
    build:
      context: .
      dockerfile: ./docker/airflow/Dockerfile
    user: airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@airflow-db:5432/airflow
      - MINIO_HOST=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - _JAVA_OPTIONS=-Xmx2g -Xms512m 
    depends_on:
      airflow-db:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      trino:
        condition: service_healthy
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./crawler:/opt/airflow/crawler
      - ./data:/opt/airflow/data
    command: > 
      bash -c "
        airflow db migrate &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin
      "
    networks:
      - airflow_net

  # superset-db:
  #   image: postgres:13
  #   container_name: superset_db
  #   environment:
  #     - POSTGRES_USER=superset
  #     - POSTGRES_PASSWORD=superset
  #     - POSTGRES_DB=superset
  #   volumes:
  #     - superset_db_data:/var/lib/postgresql/data  # Lưu trữ dữ liệu Postgres
  #   networks:
  #     - airflow_net
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U superset -d superset"]
  #     interval: 5s
  #     timeout: 5s
  #     retries: 5


  superset:
    image: apache/superset:3.0.1
    container_name: superset
    ports:
      - "8085:8088"
    environment:
      - SUPERSET_SECRET_KEY=admin
      - ADMIN_USERNAME=admin
      - ADMIN_FIRSTNAME=Superset
      - ADMIN_LASTNAME=Admin
      - ADMIN_EMAIL=admin@example.com
      - ADMIN_PASSWORD=admin
      - FLASK_APP=superset
      - SQLALCHEMY_DATABASE_URI=sqlite:////app/superset_home/superset.db  # Đảm bảo tệp `superset.db` sẽ lưu trong thư mục ngoài container
    volumes:
      - ./docker/superset:/app/superset_config  # Cấu hình Superset
      - ./superset_home:/app/superset_home  # Ánh xạ đúng thư mục vào container
    user: "root"  # Đổi thành root nếu gặp lỗi quyền
    command: >
      bash -c "
        pip install trino &&
        chown -R superset:superset /app/superset_home &&  # Đảm bảo quyền ghi vào thư mục superset_home
        su superset -c 'superset db upgrade' &&
        su superset -c 'superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@example.com --password admin' || true &&
        su superset -c 'superset init' &&
        su superset -c 'superset run -h 0.0.0.0 -p 8088 --with-threads'
      "
    networks:
      - airflow_net
    restart: unless-stopped  # Đảm bảo container sẽ tự khởi động lại khi gặp sự cố
    # Thêm restart policy để container khởi động lại khi gặp sự cố





  airflow-webserver:
    build:
      context: .
      dockerfile: ./docker/airflow/Dockerfile
    user: airflow
    ports:
      - "8081:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=gJcA1TljZDCZYOXhTFBNRoBZRDusH5m3EZEqygChqDo=
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@airflow-db:5432/airflow
      - MINIO_HOST=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - _JAVA_OPTIONS=-Xmx2g -Xms512m
      - AIRFLOW__WEBSERVER__BASE_URL=http://localhost:8080
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./crawler:/opt/airflow/crawler
      - ./data:/opt/airflow/data
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      trino:
        condition: service_healthy
    command: webserver 
    networks:
      - airflow_net

  airflow-worker:
    build:
      context: .
      dockerfile: ./docker/airflow/Dockerfile
    user: airflow
    environment:
      - AIRFLOW_UID=0
      - AIRFLOW_GID=0
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=gJcA1TljZDCZYOXhTFBNRoBZRDusH5m3EZEqygChqDo=
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@airflow-db:5432/airflow
      - MINIO_HOST=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - _JAVA_OPTIONS=-Xmx2g -Xms512m
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./crawler:/opt/airflow/crawler
      - ./data:/opt/airflow/data
    depends_on:
      airflow-scheduler:
        condition: service_started
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      trino:
        condition: service_healthy
    command: celery worker
    networks:
      - airflow_net

  airflow-scheduler:
    build:
      context: .
      dockerfile: ./docker/airflow/Dockerfile
    user: airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=gJcA1TljZDCZYOXhTFBNRoBZRDusH5m3EZEqygChqDo=
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@airflow-db:5432/airflow
      - MINIO_HOST=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - _JAVA_OPTIONS=-Xmx2g -Xms512m
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./crawler:/opt/airflow/crawler
      - ./data:/opt/airflow/data
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      trino:
        condition: service_healthy
    command: scheduler
    networks:
      - airflow_net

networks:
  airflow_net:
    driver: bridge

volumes:
  minio_data:
  mariadb_data:
  hive_metastore_data:
  pg_data:
  redis_data:
  # superset_db_data:
  superset_home:
